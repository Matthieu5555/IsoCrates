# Further Development

Orthogonal development tasks for IsoCrates, each with clear boundaries, integration points, and success metrics. Tasks are scoped so that no task is a prerequisite for another unless explicitly stated in its dependencies field.

---

## T4 — Content Migration Pipeline

Enable importing existing documentation from external platforms into IsoCrates.

**Current state:** The only ingestion path is `agent/openhands_doc.py` → git clone → AI generation → `POST /api/docs`. The document model (`backend/app/models/document.py:17-19`) already supports `repo_url = None` for standalone documents, and `source_type` property (line 60) distinguishes repository vs standalone.

**What changes:**
- New backend module: `backend/app/services/import_service.py` with adapters per source:
  - Word (.docx): file upload endpoint, parse with python-docx, convert to markdown.
  - Confluence: REST API adapter, convert storage format (XHTML) to markdown.
  - Notion: API adapter, convert block JSON to markdown.
  - Google Docs: Drive API adapter (OAuth2), export as markdown.
- New API endpoints: `POST /api/import/upload` (file-based), `POST /api/import/connect` (API-based sources).
- Content normalization: each adapter outputs markdown + a path mapping (source hierarchy → IsoCrates `path` field).
- Batch creation: call `DocumentService.create_or_update_document()` per page — no new storage logic needed.
- Source tracking: use existing `repo_url` field (nullable) for source URL, `keywords` field for source platform tag (e.g., `["Imported", "Confluence"]`).

**Files touched:**
- New: `backend/app/services/import_service.py`, `backend/app/api/imports.py`
- `backend/app/main.py` — register new router
- `backend/requirements.txt` — python-docx, mammoth, or similar
- New: `frontend/components/import/ImportDialog.tsx` (UI for upload/connect)

**Dependencies:** None strictly, but T3 (rich editor) makes the imported content editable with proper table support.

**Key success metrics:**
- [ ] A .docx file with headings, tables, and code blocks uploads and produces a valid IsoCrates document
- [ ] Imported document appears in the tree view at the correct path
- [ ] Tables in the source document are preserved as GFM tables in the imported markdown
- [ ] A Confluence space with 10+ pages imports into a matching folder hierarchy
- [ ] Re-importing the same source updates existing documents (upsert), does not create duplicates
- [ ] `source_type` returns `'standalone'` for all imported documents

---

## T12 — Performance Monitoring Dashboard

Visibility into system health and agent performance.

**Current state:** No monitoring. No metrics collection. Health check exists at `GET /health` (`backend/app/main.py`) but returns only a static OK.

**What changes:**
- Instrument the backend with Prometheus metrics (request count, latency histograms, error rates).
- Agent metrics: generation duration, token usage, success/failure rate (logged in `author_metadata` JSON, `backend/app/models/version.py`).
- Dashboard: lightweight frontend page or Grafana integration.
- Extend `/health` to return database status, document count, and last generation timestamp.

**Files touched:**
- `backend/app/main.py` — Prometheus middleware, extended health endpoint
- `backend/requirements.txt` — prometheus-fastapi-instrumentator or similar
- New: `frontend/app/admin/monitoring/page.tsx` (or Grafana config)
- `docker-compose.yml` — Prometheus + Grafana services (optional)

**Dependencies:** None.

**Key success metrics:**
- [ ] `/health` returns database connectivity status, total document count, and last generation timestamp
- [ ] Prometheus endpoint exposes request count, latency p50/p95/p99, and error rate per endpoint
- [ ] Agent generation duration is tracked and queryable (average, p95)
- [ ] An alert fires (or is configurable) when error rate exceeds 5% over a 5-minute window
- [ ] Dashboard loads and displays live data without manual configuration

---

## T16 — AI Chat Assistant

Add an AI-powered chat sidebar for navigating documentation, recommending relevant docs, and answering questions directly from documentation content.

**Current state:** No chat feature exists. Users navigate via tree and CMD+K search.

**What changes:**
- New chat service (FastAPI, separate from main backend or integrated) with endpoints: `POST /chat/query`, `GET /chat/context-preview`.
- Schema change: add `summary` column to `documents` table (20-50 word summary per doc, generated by agent).
- Chat service uses tree-based scoping to reduce context (100K docs -> 5-20 relevant docs per query), sends summaries + query to LLM, returns recommendations and/or direct answers with citations.
- Frontend: new `ChatSidebar` component with message history, scope selector (current tree position), doc chips showing context, and "add/remove from context" controls.
- Three implementation phases: (1) summary-based MVP, (2) enhanced context control UI, (3) optional embedding-based semantic search for scale.

**Key design decisions:**
- Orthogonal architecture: chat service is standalone, calls existing backend APIs.
- Summary-based approach works up to ~1000 docs per scope; tree-based filtering keeps scopes small.
- LLM proxy through backend (never expose API keys to frontend).
- Strict citation requirement to prevent hallucination.

**Files touched:**
- New: `backend/app/api/chat.py`, `backend/app/services/chat_service.py`
- New: `frontend/components/chat/ChatSidebar.tsx`
- `backend/app/models/document.py` -- add `summary` column
- New migration for `summary` field
- `agent/openhands_doc.py` -- generate summaries during doc creation
- `docker-compose.yml` -- optional separate chat service

**Dependencies:** None strictly. Better with T7 (advanced search) for fallback.

**Key success metrics:**
- [ ] User can ask a natural language question and get 2-3 relevant document recommendations with reasons
- [ ] Direct Q&A mode answers questions with citations to specific documents
- [ ] Scope selector limits context to current tree position
- [ ] Per-query cost < $0.01
- [ ] Response latency < 3 seconds

---

## T19 — XSS Sanitization

Sanitize rendered markdown to prevent stored XSS via document content.

**Current state:** Markdown rendered client-side via `remark-gfm` and `rehype-raw`. React's default escaping provides baseline protection, but `rehype-raw` allows raw HTML in markdown, which could be exploited if an attacker injects content via the agent or API.

**What changes:**
- Add `rehype-sanitize` to the markdown renderer pipeline (`frontend/components/markdown/MarkdownRenderer.tsx`).
- Use the default GitHub schema (allows safe HTML subset, strips scripts and event handlers).
- No backend changes needed — this is a frontend rendering concern.

**Files touched:**
- `frontend/components/markdown/MarkdownRenderer.tsx` — add `rehype-sanitize` plugin
- `frontend/package.json` — add `rehype-sanitize` dependency

**Dependencies:** None.

**Key success metrics:**
- [ ] `<script>alert('xss')</script>` in document content is stripped on render
- [ ] `<img onerror="alert('xss')">` is stripped
- [ ] Legitimate HTML in markdown (tables, emphasis, links) renders correctly
- [ ] Mermaid blocks still render (not stripped by sanitizer)

---

## T20 — Frontend Test Suite (DONE)

Build test infrastructure for the frontend from zero.

**Current state:** 72 frontend tests passing across 6 test files. Vitest + React Testing Library + jsdom configured. Covers API client, MarkdownRenderer, WikilinkPicker, DependencyGraph, and DocumentTree components. Also caught and fixed a real bug in `useTreeData` (error state not cleared on retry).

**What changes:**
- Add vitest + React Testing Library + jsdom
- Test critical components:
  - `MarkdownRenderer` — table rendering, mermaid rendering, wikilink handling, XSS scenarios
  - `DocumentTree` — navigation, selection, drag-drop (mocked)
  - `SearchCommand` — search flow, keyboard navigation, filter state
  - `WikiLink` — resolution, broken link styling
- Test auth flows:
  - `authStore` — login, logout, permission checks (`canRead`, `canEdit`)
  - 401 redirect behavior
- Test API client:
  - Error handling, retry logic, token injection
- CI integration: add frontend tests to GitHub Actions workflow

**Files touched:**
- New: `frontend/__tests__/` directory structure
- New: `frontend/vitest.config.ts`, `frontend/vitest.setup.ts`
- `frontend/package.json` — vitest, @testing-library/react, jsdom
- `.github/workflows/test.yml` — add frontend test step

**Dependencies:** None.

**Key success metrics:**
- [ ] `MarkdownRenderer` tests confirm GFM tables and mermaid blocks render without errors
- [ ] `DocumentTree` basic navigation tested (expand/collapse, select)
- [ ] `authStore` permission logic tested (grant matching, role hierarchy)
- [ ] API client error handling tested (401 redirect, retry on 5xx)
- [ ] CI pipeline runs frontend tests on every PR
- [ ] Coverage report generated (target: 40% initial coverage on critical components)

---

## T21 — Fix Migration Numbering (CRITICAL)

Resolve duplicate migration file numbering that can cause deployment failures.

**Current state:** Two migration files share the `006` prefix:
- `backend/migrations/006_add_indexes.sql`
- `backend/migrations/006_add_fts5.sql`

This causes non-deterministic ordering. On fresh deployments, one migration may run before the other unpredictably, or migration runners may fail entirely.

**What changes:**
- Rename `006_add_fts5.sql` to `010_add_fts5.sql` (after the highest existing number)
- Verify no other numbering conflicts exist
- Document migration ordering expectations

**Files touched:**
- Rename: `backend/migrations/006_add_fts5.sql` → `backend/migrations/010_add_fts5.sql`

**Dependencies:** None.

**Key success metrics:**
- [ ] All migration files have unique numeric prefixes
- [ ] Fresh database setup applies all migrations in correct order
- [ ] Existing deployments unaffected (migrations already applied)

---

## T22 — Require Explicit Production Config (CRITICAL)

Prevent insecure deployments by failing startup when security-critical configuration uses defaults.

**Current state:** The application starts successfully with insecure defaults:
- `jwt_secret_key = "dev-insecure-key-change-me"` — predictable, attackers can forge tokens
- `auth_enabled = False` — anyone can read/write/delete without authentication
- Startup warnings exist (T18) but don't prevent the insecure deployment

**What changes:**
- Add `ENVIRONMENT` setting: `development`, `staging`, `production`
- In `production` mode:
  - Fail startup if `JWT_SECRET_KEY` equals the default value
  - Fail startup if `AUTH_ENABLED` is False
  - Fail startup if `CORS_ALLOWED_ORIGINS` contains localhost
- In `development` mode: warn but allow (current behavior)
- Update docker-compose.yml to set `ENVIRONMENT=production` by default

**Files touched:**
- `backend/app/core/config.py` — add ENVIRONMENT setting, startup validation
- `backend/app/main.py` — call validation in startup event
- `docker-compose.yml` — set ENVIRONMENT=production
- `.env.example` — document ENVIRONMENT variable

**Dependencies:** None.

**Key success metrics:**
- [ ] Production deployment with default JWT secret fails to start with clear error message
- [ ] Production deployment with AUTH_ENABLED=false fails to start
- [ ] Development mode preserves current permissive behavior for local development
- [ ] Error messages clearly explain what configuration is required

---

## T23 — PostgreSQL Migration Path (HIGH)

Document and support PostgreSQL for production deployments with concurrent users.

**Current state:** SQLite is the only documented database. It has severe limitations:
- Single writer at a time (concurrent writes queue or fail)
- `check_same_thread=False` is a workaround, not a solution
- No connection pooling
- Risk of "database is locked" errors under load
- Risk of corruption on unclean shutdown

**What changes:**
- Add PostgreSQL service to docker-compose.yml (optional, commented out)
- Document SQLite limitations in README/DEPLOYING_AT_YOUR_ORGANIZATION.md
- Test all queries work on PostgreSQL (especially FTS5 → PostgreSQL full-text search)
- Add connection pooling configuration for PostgreSQL
- Update health check to verify database connectivity with actual query

**Files touched:**
- `docker-compose.yml` — add PostgreSQL service (optional)
- `backend/app/database.py` — PostgreSQL connection pooling
- `docs/DEPLOYING_AT_YOUR_ORGANIZATION.md` — document database options and limitations
- `backend/app/repositories/document_repository.py` — abstract FTS5 vs PostgreSQL FTS

**Dependencies:** None.

**Key success metrics:**
- [ ] docker-compose supports both SQLite (default) and PostgreSQL (production)
- [ ] All existing tests pass with PostgreSQL backend
- [ ] Search works on PostgreSQL (using `to_tsvector`/`to_tsquery` instead of FTS5)
- [ ] Documentation clearly states "use PostgreSQL for multi-user deployments"
- [ ] Health check performs actual database query, not just connection check

---

## T24 — Break Circular Service Dependencies (HIGH)

Eliminate implicit coupling between DocumentService and DependencyService.

**Current state:** `DocumentService` instantiates `DependencyService` internally:
```python
# document_service.py:11
from ..services.dependency_service import DependencyService

class DocumentService:
    def __init__(self, db: Session):
        self.dep_service = DependencyService(db)  # Hard-coded
```

Both services can mutate versions. Callers of `DocumentService.update_document()` cannot predict that dependencies and potentially other documents' wikilinks will be modified.

**What changes:**
- Option A (Coordinator pattern): Create `DocumentCoordinator` that orchestrates both services
- Option B (Event pattern): DocumentService emits events, DependencyService subscribes
- Option C (Explicit composition): API layer explicitly calls both services in sequence

Recommended: Option C for simplicity — move orchestration to API layer where transaction boundaries are clearer.

**Files touched:**
- `backend/app/services/document_service.py` — remove DependencyService instantiation
- `backend/app/api/documents.py` — explicitly call both services
- `backend/app/services/dependency_service.py` — no changes needed

**Dependencies:** None.

**Key success metrics:**
- [ ] DocumentService has no imports from other services
- [ ] DependencyService has no imports from other services
- [ ] Each service can be unit tested in complete isolation
- [ ] Transaction boundaries are explicit in API layer
- [ ] No change in external API behavior

---

## T25 — Standardize Service Return Types (HIGH)

Eliminate return type inconsistency across services.

**Current state:** Services return a mix of:
- ORM models (`Document`, `User`)
- Pydantic schemas (`DocumentListResponse`, `TreeNode`)
- Raw dicts (`search_documents()` returns `list[dict]`)

Callers must know which layer does type conversion. This creates maintenance burden and type safety gaps.

**What changes:**
- All public service methods return Pydantic schemas (DTOs)
- Private helper methods may use ORM models internally
- `search_documents()` returns `list[SearchResultResponse]`, not `list[dict]`
- Update all callers to use schema types

**Files touched:**
- `backend/app/services/document_service.py` — return schemas from all public methods
- `backend/app/services/folder_service.py` — return schemas
- `backend/app/schemas/document.py` — ensure all response types exist
- `backend/app/api/*.py` — update type hints

**Dependencies:** None.

**Key success metrics:**
- [ ] No public service method returns `dict` or `list[dict]`
- [ ] All public service methods have explicit return type hints
- [ ] Type checker (mypy/pyright) passes with strict mode
- [ ] API layer does no manual dict-to-schema conversion

---

## T26 — Repository Exception Pattern (MEDIUM)

Make repositories raise exceptions instead of returning None/False.

**Current state:** All repositories return `None` or `False` on failures:
```python
def get_by_id(self, doc_id: str) -> Optional[Document]:
    return self._active_query().filter(...).first()  # Returns None if not found
```

Services must defensively check every return value and re-raise as custom exceptions. This is boilerplate that will be forgotten.

**What changes:**
- Repositories raise `DocumentNotFoundError`, `VersionNotFoundError`, etc.
- Add `get_by_id_optional()` for cases where None is legitimate
- Remove defensive checks from services
- Update exception hierarchy if needed

**Files touched:**
- `backend/app/repositories/document_repository.py` — raise on not found
- `backend/app/repositories/version_repository.py` — raise on not found
- `backend/app/repositories/dependency_repository.py` — raise on not found
- `backend/app/services/*.py` — remove defensive None checks

**Dependencies:** None.

**Key success metrics:**
- [ ] `repo.get_by_id(invalid_id)` raises `DocumentNotFoundError`
- [ ] Services have 50%+ fewer `if not result: raise` patterns
- [ ] All existing tests pass (behavior unchanged at API level)
- [ ] Stack traces point directly to repository layer on not-found errors

---

## T27 — Split DocumentTree Component (DONE)

Break the 676-line monolithic component into testable pieces.

**Current state:** Component reduced from 676 → 471 lines. Three hooks extracted: `useTreeData` (data loading, refresh, generation status), `useTreeDragDrop` (drag state, drop handlers, validation), `useTreeSelection` (multi-select with Ctrl/Cmd+click). Zero TypeScript errors, all behavior preserved.

**What changes:**
- Extract `useTreeData` hook — data loading, refresh, optimistic updates
- Extract `useTreeDragDrop` hook — drag state, drop handlers, validation
- Extract `useTreeSelection` hook — multi-select state, Ctrl/Cmd+click logic
- Extract `TreeContextMenu` component — context menu rendering and actions
- Keep `DocumentTree` as thin orchestrator composing these pieces

**Files touched:**
- `frontend/components/tree/DocumentTree.tsx` — reduce to ~200 lines
- New: `frontend/hooks/useTreeData.ts`
- New: `frontend/hooks/useTreeDragDrop.ts`
- New: `frontend/hooks/useTreeSelection.ts`
- New: `frontend/components/tree/TreeContextMenu.tsx`

**Dependencies:** T20 (frontend tests) makes this safer to do.

**Key success metrics:**
- [ ] `DocumentTree.tsx` is under 250 lines
- [ ] Each extracted hook is independently testable
- [ ] No change in user-facing behavior
- [ ] Drag-drop, selection, and context menu work exactly as before

---

## T28 — Add Migration Runner (MEDIUM)

Replace raw SQL files with proper migration management.

**Current state:** Migrations are raw `.sql` files with no:
- Version tracking (which migrations have been applied?)
- Automatic execution on startup
- Rollback automation
- Dependency ordering enforcement

Deployments require manually running SQL files in order.

**What changes:**
- Add Alembic for SQLAlchemy migration management
- Convert existing SQL files to Alembic migrations
- Add `alembic upgrade head` to startup or entrypoint
- Track migration state in `alembic_version` table

**Files touched:**
- New: `backend/alembic/` directory structure
- New: `backend/alembic.ini`
- `backend/app/main.py` or `Dockerfile` — run migrations on startup
- Keep `backend/migrations/*.sql` as reference (or convert to Alembic)

**Dependencies:** T21 (fix numbering) should be done first.

**Key success metrics:**
- [ ] `alembic upgrade head` applies all pending migrations
- [ ] `alembic downgrade -1` rolls back the last migration
- [ ] Fresh deployment automatically has correct schema
- [ ] Migration history queryable via `alembic history`

---

## T29 — Audit Log Retention (LOW)

Prevent unbounded growth of the audit_log table.

**Current state:** `audit_log` table has no retention policy. Every state-changing operation adds a row. Over years, this will grow to millions of rows, slowing queries and consuming storage.

**What changes:**
- Add retention policy: delete audit entries older than 1 year (configurable)
- Add startup purge job (similar to trash purge in `main.py`)
- Add `created_at` index if not present
- Document retention policy in DEPLOYING_AT_YOUR_ORGANIZATION.md

**Files touched:**
- `backend/app/services/audit_service.py` — add `purge_old_entries(days=365)`
- `backend/app/main.py` — call purge on startup
- `backend/app/core/config.py` — add `AUDIT_RETENTION_DAYS` setting
- `docs/DEPLOYING_AT_YOUR_ORGANIZATION.md` — document retention

**Dependencies:** None.

**Key success metrics:**
- [ ] Audit entries older than retention period are automatically deleted
- [ ] Purge runs on every application startup
- [ ] Retention period is configurable via environment variable
- [ ] Purge completes in < 5 seconds for tables with 1M+ rows

---

## T30 — Database Backup Strategy (LOW)

Document and automate database backups.

**Current state:** No backup strategy documented. SQLite file could be lost on disk failure. No point-in-time recovery possible.

**What changes:**
- Document manual backup commands for SQLite and PostgreSQL
- Add backup script to docker-compose (optional cron service)
- Document restore procedure
- For SQLite: simple file copy while app is stopped, or `.backup` command
- For PostgreSQL: `pg_dump` with compression

**Files touched:**
- `docs/DEPLOYING_AT_YOUR_ORGANIZATION.md` — backup and restore procedures
- New: `scripts/backup.sh` — backup script
- `docker-compose.yml` — optional backup service (cron-based)

**Dependencies:** T23 (PostgreSQL support) for PostgreSQL backup docs.

**Key success metrics:**
- [ ] DEPLOYING_AT_YOUR_ORGANIZATION.md has clear backup instructions for both database types
- [ ] Backup script works for SQLite and PostgreSQL
- [ ] Restore procedure tested and documented
- [ ] Backup frequency recommendation documented (daily minimum)

---

## Dependency Graph

```
COMPLETED:
T1  (Multi-Page Agent)          T2  (Rich Content Prompts)
T3  (TipTap Editor)             T5  (Testing Suite - backend)
T6  (JWT Auth)                  T7  (Advanced Search / FTS5)
T8  (Auto Regeneration)         T9  (DB Indexes)
T10 (Wikilink Resolution)       T11 (Rate Limiting)
T13 (Bulk Operations)           T14 (Soft Delete)
T15 (OpenAPI Docs)              T17 (Permission System)
T18 (Startup Safety Warnings)   T19 (XSS Sanitization)
T21 (Fix Migration Numbering)   T22 (Require Prod Config)
T23 (PostgreSQL Path)           T24 (Break Service Deps)
T25 (Standardize Return Types)  T26 (Repository Exceptions)
T29 (Audit Log Retention)       T30 (Database Backup)

T20 (Frontend Tests)            T27 (Split DocumentTree)

OPEN — MEDIUM:
T4  (Content Migration)         — standalone, better with T3
T28 (Migration Runner)          — after T21

OPEN — LOW:
T12 (Monitoring Dashboard)      — standalone
T16 (AI Chat Assistant)         — standalone, better with T7
T31 (Sample Data / Seed Script) — standalone
```

No task blocks another. All are independently shippable. "Better with/after" indicates synergy, not hard dependency.

---

## T31 — Sample Data / Seed Script (LOW)

Provide sample data for fresh deployments so new users and evaluators can explore the product immediately.

**Current state:** A fresh install is completely empty. The first user must be created via `curl`, and all documents must be generated or manually created. This makes initial evaluation harder than it should be.

**What changes:**
- Create `scripts/seed.py` that populates a fresh database with:
  - An admin user (with a documented default password)
  - A small folder hierarchy (3-5 folders)
  - 5-10 sample documents with realistic markdown content, wikilinks, and metadata
  - A few dependency relationships between documents
- The script should be idempotent (safe to run multiple times)
- Clearly documented as development/demo only — never run in production

**Files touched:**
- New: `scripts/seed.py`
- `README.md` — mention seed script in quick start
- `docs/DEPLOYING_AT_YOUR_ORGANIZATION.md` — mention availability for evaluation

**Dependencies:** None.

**Key success metrics:**
- [ ] `python scripts/seed.py` populates an empty database with sample content
- [ ] The tree view shows a meaningful folder structure after seeding
- [ ] Wikilinks between sample docs resolve correctly
- [ ] Dependency graph shows relationships
- [ ] Running the script twice does not create duplicates

---

## T32 — Content Chunk Embeddings for Paragraph-Level RAG (MEDIUM)

**Current state:** The system supports description-level embeddings — one vector per
document based on its 2-3 sentence summary. This is good for document discovery
("find documents about authentication") but not for paragraph-level retrieval
("what's the exact configuration syntax for JWT tokens?").

**Goal:** Add content chunk embeddings so that individual paragraphs/sections within
a document can be retrieved via semantic search, enabling RAG-quality retrieval.

**Architecture:**

New `document_chunks` table:
```sql
CREATE TABLE document_chunks (
    id TEXT PRIMARY KEY,
    doc_id TEXT NOT NULL REFERENCES documents(id) ON DELETE CASCADE,
    chunk_index INTEGER NOT NULL,
    chunk_text TEXT NOT NULL,
    chunk_embedding vector(N),
    created_at TIMESTAMP DEFAULT NOW()
);
CREATE INDEX idx_chunks_doc_id ON document_chunks(doc_id);
CREATE INDEX idx_chunks_embedding ON document_chunks
    USING hnsw (chunk_embedding vector_cosine_ops)
    WHERE chunk_embedding IS NOT NULL;
```

**Chunking strategy:**
- Split documents by heading (## boundaries)
- Each chunk ~300-500 tokens with overlap
- Store chunk position for context reconstruction
- Re-chunk on document update (delete old chunks, create new ones)

**Re-ranking:**
- Initial retrieval: top-50 chunks via vector search
- Re-rank with cross-encoder model for precision
- Return top-5 chunks with document context

**Acceptance criteria:**
- [ ] `document_chunks` table with vector column (PostgreSQL only)
- [ ] Chunking runs asynchronously after document create/update
- [ ] `GET /api/docs/search/?mode=chunk` returns paragraph-level results
- [ ] MCP `search_docs` tool can use chunk-level retrieval
- [ ] Chunk count visible in document metadata
- [ ] Re-chunking on content update is idempotent
- [ ] Cross-encoder re-ranking improves precision vs raw vector search

---

## Priority Order for "Deploy and Forget" Robustness

**Pre-production (DONE):**
1. ~~T21 — Fix Migration Numbering~~ ✓
2. ~~T22 — Require Explicit Production Config~~ ✓
3. ~~T19 — XSS Sanitization~~ ✓
4. ~~T23 — PostgreSQL Migration Path~~ ✓

**Post-deployment hardening (DONE):**
5. ~~T24 — Break Circular Service Dependencies~~ ✓
6. ~~T25 — Standardize Service Return Types~~ ✓

**Testing & refactoring (DONE):**
7. ~~T20 — Frontend Test Suite~~ ✓ (72 tests across 6 files)
8. ~~T26 — Repository exception pattern~~ ✓
9. ~~T27 — Split DocumentTree~~ ✓ (676 → 471 lines)
10. ~~T29 — Audit log retention~~ ✓
11. ~~T30 — Database backup script~~ ✓

**Remaining:**
12. T28 — Migration runner (low priority — manual migrations work)
13. T4, T12, T16, T31 — Feature additions
14. T32 — Content chunk embeddings (builds on description-level embeddings)
